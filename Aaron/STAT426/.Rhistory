#lack of fit (sigma^2 unknown)
plot(colonies ~ log(dose + 1), data = salmonella)
abline(coef(mod1))
mod1f = lm(colonies ~ factor(log(dose + 1)), data = salmonella)
cbind(salmonella,mod1f$fitted)[order(salmonella$dose)]
cbind(salmonella,mod1f$fitted)[order(salmonella$log(dose + 1)]
cbind(salmonella,mod1f$fitted)[order(salmonella$log(dose + 1))]
mod1f = lm(colonies ~ factor(dose), data = salmonella)
cbind(salmonella,mod1f$fitted)[order(salmonella$dose)]
cbind(salmonella,mod1f$fitted)[order(salmonella$dose),]
#Anova test
anova(mod1,mod1f)
#Anova test
lof_Anova = anova(mod1,mod1f)
lof_Anova
names(lof_Anova)
lof_Anova$F
lof_Anova$F[2]
lof_Anova[Df]
lof_Anova$Df
lof_Anova$Res.Df
1-pf(lof_Anovaq$F[2],lof_Anova$Res.Df[2],lof_Anova$Df[2])
#Anova test
lof_Anova = anova(mod1,mod1f)
1-pf(lof_Anova$F[2],lof_Anova$Res.Df[2],lof_Anova$Df[2])
lof_Anova$Res.Df
1-pf(lof_Anova$F[2],1-lof_Anova$Df[2],lof_Anova$Df[2])
lof_Anova
1-pf(lof_Anova$F[2],4,5)
1-pf(lof_Anova$F[2],4,12)
#Problem 2
data(gammaray)
head(gammaray)
mod1 = lm(colonies ~ log(I(dose + 1)), data = salmonella)
summary(mod1)
mod1 = lm(colonies ~ log(dose + 1), data = salmonella)
summary(mod1)
#Problem 2
data(gammaray)
head(gammaray)
mod2 = lm(flux ~ time, data = gammaray, weights = 1/error )
data("strongx")
head(strongx)
View(gammaray)
View(strongx)
summary(mod2u)
mod2u = lm(flux ~ time, data = gammaray)
summary(mod2u)
#Problem 2
data(gammaray)
mod2 = lm(flux ~ time, data = gammaray, weights = 1/error^2 )
summary(mod2)
summary(mod2)$sig
summary(mod2)$Df
names(summary(mod2))
summary(mod2)$df
#lack of fit test (sigma^2 known, it's given as the error column)
1-pchisq(summary(mod2)$sig^2*sumary(mod2)$df[2],sumary(mod2)$df[2])
#lack of fit test (sigma^2 known, it's given as the error column)
1-pchisq(summary(mod2)$sig^2*61,61
#lack of fit test (sigma^2 known, it's given as the error column)
1-pchisq(summary(mod2)$sig^2*61,61)
#lack of fit test (sigma^2 known, it's given as the error column)
1-pchisq(summary(mod2)$sig^2*61,61)
#weighted model
mod2 = lm(flux ~ time, data = gammaray, weights = 1/error^2 )
summary(mod2)
summary(mod2)$sig^2
#estimate sigma-sq
cbind(summary(mod2u)$sig^2, sum(gu$res^2)/61)
#estimate sigma-sq
cbind(summary(mod2u)$sig^2, sum(mod2u$res^2)/61)
#WLS, these two do not agree
summary(mod2)$sig^2
legend("topleft", col=c("red"), lty=c(1,2), legend=c("WLS"))
#Problem 2
data(gammaray)
#weighted model
mod2 = lm(flux ~ time, data = gammaray, weights = 1/error^2 )
summary(mod2)
plot(flux ~ time, data = gammaray, cex=sd);
plot(flux ~ time, data = gammaray, cex=error);
points(flux ~ time, data=gammaray, pch=2)
abline(mod2, col="red", lty=1, lwd=2);
legend("topleft", col=c("red"), lty=c(1,2), legend=c("WLS"))
#Trying with poly nomials
mod2sq = lm(flux ~ time + I(time^2), data = gammaray, weights = 1/error^2 )
anova(mod2,mod2sq)
group = data.frame(x=c(0,1,2), number of trials =c(1,1,1), Y = c(1,2,1))
#Problem 2
data(gammaray)
mod2 = lm(flux ~ time, data = gammaray, weights = 1/error^2 )
round(summary(mod2)$coef,dig = 3)
g2 = lm(flux ~ time + I(time^2), data = gammaray, weights = 1/error^2)
round(summary(g2)$coef,dig=3)
g3 = lm(flux ~ time + I(time^2) + I(time^3), data = gammaray , weights = 1/error^2)
round(summary(g3)$coef,dig=3) # Select d=2
summary(mod2)
mod2 = glm(flux ~ time, data = gammaray, weights = 1/error^2 )
summary(mod2)
mod2 = lm(flux ~ time, data = gammaray, weights = 1/error^2 )
summary(mod2)
#Problem 2
data(gammaray)
mod2 = lm(flux ~ time, data = gammaray, weights = 1/error^2 )
summary(mod2)
g2 = lm(flux ~ time + I(time^2), weights = sd^-2, gammaray)
round(summary(g2)$coef,dig=3)
g3 = lm(flux ~ time + I(time^2) + I(time^3) , weights = sd^-2, gammaray)
round(summary(g3)$coef,dig=3)
g4 = lm(flux ~ time + I(time^2) + I(time^3) + I(time^4), weights = sd^-2, gammaray)
round(summary(g4)$coef,dig=3)
g2 = lm(flux ~ time + I(time^2), weights = error^-2, gammaray)
round(summary(g2)$coef,dig=3)
g3 = lm(flux ~ time + I(time^2) + I(time^3) , weights = error^-2, gammaray)
round(summary(g3)$coef,dig=3)
g4 = lm(flux ~ time + I(time^2) + I(time^3) + I(time^4), weights = error^-2, gammaray)
round(summary(g4)$coef,dig=3)
#Problem 3
data(longley)
head(longley)
mod3 = lm(Employed~.,data = longley)
e$val
#a
#condition number
m3_mat = model.matrix(mod3)[,-1]
e = eigen(t(m3_mat) %.% m3_mat)
e$val
e = eigen(t(m3_mat) %*% m3_mat)
e$val
e$val
summary(mod3)
e$val
length(longley)
#standardize matrix
m3_mat = model.matrix(mod3)[,-1]
m3_mat = m3_mat - matrix(apply(m3_mat, 2, mean), 7,6, byrow = T)
m3_mat = m3_mat - matrix(apply(m3_mat, 2, mean), 7,6, byrow = T)
longley
length(longley)
rowsum(longley)
count(longley)
View(longley)
m3_mat = m3_mat - matrix(apply(m3_mat, 2, mean), 16,6, byrow = T)
m3_mat = m3_mat / matrix(apply(m3_mat, 2, sd), 16,6, byrow = T)
apply(m3_mat,2,mean)
apply(m3_mat,2,var)
sqrt(e$val[1]/e$val)
#condition number
e = eigen(t(m3_mat) %*% m3_mat)
sqrt(e$val[1]/e$val)
#b
round(vif(m3_mat), dig=2)
#b
#pairwise correlation
round(cor(longley), dig=2)
#c
round(vif(m3_mat), dig=2)
sqrt(vif(m3_mat)$GNP)
sqrt(vif(m3_mat)$[2])
#GNP
sqrt(1788.51)
#Year
sqrt(758.98)
#Population
sqrt(399.15)
#b
#pairwise correlation
round(cor(longley), dig=2)
#Problem
#a
#Backward Elimination
modA = glm(Y ~ ., data = sore,family = binomial)
sore=data.frame(read.csv(file="sore.csv",header=T))
setwd("/Users/chanm/Downloads")
sore=data.frame(read.csv(file="sore.csv",header=T))
drop1(modA, test = "Chisq")
#Problem
#a
#Backward Elimination
modA = glm(Y ~ ., data = sore,family = binomial)
summary(modA) #AIC=36.138
names(modA)
modA$aic
drop1(modA, test = "Chisq")
#Correlation Measures
cor(sore$Y, fitted(modA))
cor(sore$Y, fitted(modB))
cor(sore$Y, fitted(modB2))
#b
modB = glm(Y ~ D, data = sore, family = binomial)
modB2 = glm(Y ~ T, data = sore, family = binomial)
cor(sore$Y, fitted(modB))
cor(sore$Y, fitted(modB2))
#Likelihood Measures
modB3 = glm(Y ~ 1, data = sore, family = binomial)
as.numeric((logLik(modA) - logLik(modA)) / (0 - logLik(modA)))
as.numeric((logLik(modB) - logLik(modA)) / (0 - logLik(modA)))
as.numeric((logLik(modB2) - logLik(modA)) / (0 - logLik(modA)))
as.numeric((logLik(modA) - logLik(mod0)) / (0 - logLik(mod0)))
as.numeric((logLik(modB) - logLik(mod0)) / (0 - logLik(mod0)))
#Likelihood Measures
mod0 = glm(Y ~ 1, data = sore, family = binomial)
as.numeric((logLik(modA) - logLik(mod0)) / (0 - logLik(mod0)))
as.numeric((logLik(modB) - logLik(mod0)) / (0 - logLik(mod0)))
as.numeric((logLik(modB2) - logLik(mod0)) / (0 - logLik(mod0)))
#Part C: Classification Tables
p0 = 0.5
table(y = sore$Y, yhat = as.numeric(fitted(modA) > p0))
21/(21+1) #sensitivity
9/(9+4) #specificity
#Part C: Classification Tables
p0 = 0.5
tab1 = table(y = sore$Y, yhat = as.numeric(fitted(modA) > p0))
tab1[2,2]/(tab1[2,2]+tab1[2,1])
tab1[1,2]/(tab1[1,2]+tab1[1,2])
tab1[1,1]/(tab1[1,1]+tab1[1,2])
tab1 = table(y = sore$Y, yhat = as.numeric(fitted(modA) > p0))
tab1[2,2]/(tab1[2,2]+tab1[2,1])#sensitivity
tab1[1,1]/(tab1[1,1]+tab1[1,2])#specificity
tab2 = table(y=sore$Y,yhat=as.numeric(fitted(modB)>p0))
tab2[2,2]/(tab2[2,2]+tab2[2,1])#sensitivity
tab2[1,1]/(tab2[1,1]+tab2[1,2])#specificity
tab3 = table(y=sore$Y,yhat=as.numeric(fitted(modB2)>p0))
tab3[2,2]/(tab3[2,2]+tab3[2,1])#sensitivity
tab3[1,1]/(tab3[1,1]+tab3[1,2])#specificity
pi0 = mean(sore$Y)
tab1a = table(y = sore$Y,yhat=as.numeric(fitted(modA)>pi0))
tab1a[2,2]/(tab1a[2,2]+tab1a[2,1])#sensitivity
tab1a[1,1]/(tab1a[1,1]+tab1a[1,2])#specificity
tab2a = table(y=sore$Y,yhat=as.numeric(fitted(modB)>pi0))
tab2a[2,2]/(tab2a[2,2]+tab2a[2,1])#sensitivity
tab2a[1,1]/(tab2a[1,1]+tab2a[1,2])#specificity
tab3a = table(y=sore$Y,yhat=as.numeric(fitted(modB2)>pi0))
tab3a[2,2]/(tab3a[2,2]+tab3a[2,1])#sensitivity
tab3a[1,1]/(tab3a[1,1]+tab3a[1,2])#specificity
setwd("/Users/chanm/Downloads")
sore=data.frame(read.csv(file="sore.csv",header=T))
#Part A
#Backward Elimination Method
mod1=glm(Y~., data=sore,family=binomial)
summary(mod1) #AIC=36.138
drop1(mod1,test="Chisq")
#Part B
mod2=glm(Y~D,data=sore,family=binomial)
mod3=glm(Y~T,data=sore,family=binomial)
#Correlation Measures
cor(sore$Y,fitted(mod1))
cor(sore$Y,fitted(mod2))
cor(sore$Y,fitted(mod3))
#Model 1 produces the best correlation measure since that gave us the highest value
#Likelihood Measures
mod0=glm(Y~1,data=sore,family=binomial)
as.numeric((logLik(mod1)-logLik(mod0))/(0-logLik(mod0)))
as.numeric((logLik(mod2)-logLik(mod0))/(0-logLik(mod0)))
as.numeric((logLik(mod3)-logLik(mod0))/(0-logLik(mod0)))
#Part C: Classification Tables
p0=0.5
table(y=sore$Y,yhat=as.numeric(fitted(mod1)>p0))
21/(21+1) #sensitivity
9/(9+4) #specificity
table(y=sore$Y,yhat=as.numeric(fitted(mod2)>p0))
17/(17+5) #sensitivity
9/(9+4) #specificity
table(y=sore$Y,yhat=as.numeric(fitted(mod3)>p0))
14/(14+8) #sensitivity
9/(9+4) #specificity
tab1 = table(y = sore$Y, yhat = as.numeric(fitted(modA) > p0))
tab1[2,2]/(tab1[2,2]+tab1[2,1])#sensitivity
tab1[1,1]/(tab1[1,1]+tab1[1,2])#specificity
tab2[2,2]/(tab2[2,2]+tab2[2,1])#sensitivity
tab2[1,1]/(tab2[1,1]+tab2[1,2])#specificity
tab3 = table(y=sore$Y,yhat=as.numeric(fitted(modB2)>p0))
tab3[2,2]/(tab3[2,2]+tab3[2,1])#sensitivity
tab3[1,1]/(tab3[1,1]+tab3[1,2])#specificity
tab1a[2,2]/(tab1a[2,2]+tab1a[2,1])#sensitivity
tab1a[1,1]/(tab1a[1,1]+tab1a[1,2])#specificity
tab2a = table(y=sore$Y,yhat=as.numeric(fitted(modB)>pi0))
tab2a[2,2]/(tab2a[2,2]+tab2a[2,1])#sensitivity
tab2a[1,1]/(tab2a[1,1]+tab2a[1,2])#specificity
pi0=mean(sore$Y)
table(y=sore$Y,yhat=as.numeric(fitted(mod1)>pi0))
18/(18+4) #sensitivity
10/(10+3) #specificity
#Part D
#ROC Curve
pihat = fitted(modA)
f.neg = c(0, cumsum(tapply(sore$Y,pihat,sum)))
t.neg = c(0, cumsum(table(pihat))) - f.neg
plot(1 - t.neg / max(t.neg),1 - f.neg / max(f.neg),type="l",main="ROC Curve",xlab="1-Specificity",ylab="Sensitivity",asp=1)
abline(a = 0,b = 1,lty = 2,col = "blue")
#Concordance Index
mean(outer(pihat[sore$Y==1],pihat[sore$Y==0],">") + 0.5*outer(pihat[sore$Y==1],pihat[sore$Y==0],"=="))
#e
par(mfrow=c(2,2))
plot(mod1)
library(vcdExtra)  # has Alligator data set
install.packages("vcdExtra")
library(vcdExtra)  # has Alligator data set
Alligator
alli <- reshape(Alligator, v.names="count", timevar="food",
idvar=c("lake","sex","size"), direction="wide")
alli
install.packages("VGAM")
library(VGAM)  # has model-fitting functions
mod1 <- vglm(cbind(count.invert,count.reptile,count.bird,count.other,
count.fish) ~ size + lake + sex,
family=multinomial, data=alli)
mod2 <- vglm(cbind(count.invert,count.reptile,count.bird,count.other,
count.fish) ~ size + lake,
family=multinomial, data=alli)
library(vcdExtra)  # has Alligator data set
Alligator
alli <- reshape(Alligator, v.names="count", timevar="food",
idvar=c("lake","sex","size"), direction="wide")
alli
Smoke.dat = data.frame(
Age = c(rep("35-44",2),rep("45-54",2),rep("55-64",2),rep("65-74",2),rep("75-85",2)),
PersonYears = c(18793,52407,10673,43248,5710,28612,2585,12663,1462,5317),
Smoke = c(rep(c("no","yes"),5)),
Deaths = c(2,32,12,104,28,206,28,186,31,102)
)
Smoke.dat
rep(c("D","R","I"),4)
c(rep(c("D","R","I"),4))
GSS = data.frame(
Gender = c(rep("Male",6),rep("Female",6)),
Race = c(rep("White",3),rep("Black",3),rep("White",3),rep("Black",3)),
Party = c(rep(c("D","R","I"),4)),
Count = c("132","176","127","42","6","12","172","129","130","56","4","15")
)
GSS
library(vcdExtra)  # has Alligator data set
Alligator
alli <- reshape(Alligator, v.names="count", timevar="food",
idvar=c("lake","sex","size"), direction="wide")
alli
gss = reshape(GSS, v.names="Count", timevar="Party",
idvar=c("D","R","I"), direction="wide")
#Create data
GSS = data.frame(
Gender = c(rep("Male",6),rep("Female",6)),
Race = c(rep("White",3),rep("Black",3),rep("White",3),rep("Black",3)),
Party = c(rep(c("D","R","I"),4)),
Count = c("132","176","127","42","6","12","172","129","130","56","4","15")
)
GSS
gss = reshape(GSS, v.names="Count", timevar="Party",
idvar=c("D","R","I"), direction="wide")
gss = reshape(GSS, v.names="Count", timevar="Party",
idvar=c("Gender","Race"), direction="wide")
gss
#model
mod = vglm(cbind(D,R,I) ~ Gender + Race, family = multinomial, data = gss)
#model
mod = vglm(cbind(Count.D, Count.R, Count.I) ~ Gender + Race, family = multinomial, data = gss)
library(vcdExtra)  # has Alligator data set
Alligator
alli <- reshape(Alligator, v.names="count", timevar="food",
idvar=c("lake","sex","size"), direction="wide")
alli
library(VGAM)  # has model-fitting functions
mod1 <- vglm(cbind(count.invert,count.reptile,count.bird,count.other,
count.fish) ~ size + lake + sex,
family=multinomial, data=alli)
#model
mod = vglm(cbind(Count.D, Count.R, Count.I) ~ Gender + Race, family = multinomial, data = gss)
#Independent is the baseline category in this case (we put it last)
summary(mod)
llrts <- deviance(mod2) - deviance(mod1)
llrts.df <- df.residual(mod2) - df.residual(mod1)
llrts
llrts.df
1 - pchisq(llrts, llrts.df)
AIC(mod1)
AIC(mod2)
summary(mod2)
fitted(mod2)
exp(1.458)
exp(1.458 + c(-1,1)*1.96*0.3959)  # approx. 95% Wald CI
#model
mod = vglm(cbind(Count.D, Count.R, Count.I) ~ Gender + Race, family = multinomial, data = gss)
#model
mod = vglm(cbind(count.D, Count.R, Count.I) ~ Gender + Race, family = multinomial, data = gss)
#model
mod = vglm(cbind(count.D, count.R, count.I) ~ Gender + Race, family = multinomial, data = gss)
#Independent is the baseline category in this case (we put it last)
summary(mod)
#model
mod = vglm(cbind(Count.D, Count.R, Count.I) ~ Gender + Race, family = multinomial, data = gss)
library(VGAM)
#Create data
GSS = data.frame(
Gender = c(rep("Male",6),rep("Female",6)),
Race = c(rep("White",3),rep("Black",3),rep("White",3),rep("Black",3)),
Party = c(rep(c("D","R","I"),4)),
Count = c("132","176","127","42","6","12","172","129","130","56","4","15")
)
GSS
#Organize data
gss = reshape(GSS, v.names = "Count", timevar = "Party",
idvar = c("Gender","Race"), direction = "wide")
gss
#model
mod = vglm(cbind(Count.D, Count.R, Count.I) ~ Gender + Race, family = multinomial, data = gss)
#Independent is the baseline category in this case (we put it last)
summary(mod)
#Problem 1
party<-data.frame(Gender=c("Male","Male","Female","Female"),
Race=c("White","Black","White","Black"),
Party=c("Democrat","Democrat","Democrat","Democrat","Republican","Republican","Republican","Republican","Independent","Independent","Independent","Independent"),
Count=c(132,42,172,56,176,6,129,4,127,12,130,15))
party
par<-reshape(party,v.names="Count",timevar="Party",idvar=c("Gender","Race"),direction="wide")
par
library(VGAM)
mod=vglm(cbind(Count.Democrat,Count.Republican,Count.Independent)~Gender+Race,family=multinomial,data=par)
summary(mod)
#Create data
GSS = data.frame(
Gender = c(rep("Male",6),rep("Female",6)),
Race = c(rep("White",3),rep("Black",3),rep("White",3),rep("Black",3)),
Party = c(rep(c("D","R","I"),4)),
Count = c("132","176","127","42","6","12","172","129","130","56","4","15")
)
GSS
#Organize data
gss = reshape(GSS, v.names = "Count", timevar = "Party",
idvar = c("Gender","Race"), direction = "wide")
gss
#model
mod = vglm(cbind(Count.D, Count.R, Count.I) ~ Gender + Race, family = multinomial, data = gss)
#Independent is the baseline category in this case (we put it last)
summary(mod)
#Create data
GSS = data.frame(
Gender = c(rep("Male",2),rep("Female",2)),
Race = c(rep(c("White","Black"),2))
Party = c(rep("D",4),rep("R",4),rep("I",4)),
Count = c("132","176","127","42","6","12","172","129","130","56","4","15")
)
#Create data
GSS = data.frame(
Gender = c(rep("Male",2),rep("Female",2)),
Race = c(rep(c("White","Black"),2)),
Party = c(rep("D",4),rep("R",4),rep("I",4)),
Count = c("132","176","127","42","6","12","172","129","130","56","4","15")
)
GSS
#Organize data
gss = reshape(GSS, v.names = "Count", timevar = "Party",
idvar = c("Gender","Race"), direction = "wide")
gss
#Create data
GSS = data.frame(
Gender = c(rep("Male",2),rep("Female",2)),
Race = c(rep(c("White","Black"),2)),
Party = c(rep("D",4),rep("R",4),rep("I",4)),
Count = c(132,42,172,56,176,6,129,4,127,12,130,15)
)
GSS
#Organize data
gss = reshape(GSS, v.names = "Count", timevar = "Party",
idvar = c("Gender","Race"), direction = "wide")
gss
#model
mod = vglm(cbind(Count.D, Count.R, Count.I) ~ Gender + Race, family = multinomial, data = gss)
#Independent is the baseline category in this case (we put it last)
summary(mod)
#Problem 2
setwd("/Users/chanm/Desktop")
auto = data.frame(read.table(file = "auto.csv", header = T))
View(auto)
View(auto)
auto = data.frame(read.csv(file = "auto.csv", header = T))
View(auto)
View(auto)
happiness <- read.table("happiness.txt", header=TRUE)
head(happiness)
View(happiness)
View(auto)
View(auto)
gss
GSS
GSS
mod2 <- vglm(cbind(X1, X2, X3, X4, X5) ~ G + L + S + I(L*S), family = cumulative(parallel = TRUE), data = auto)
mod2 <- vglm( ~ G + L + S + L*S), family = cumulative(parallel = TRUE), data = auto)
mod2 <- vglm(X1 ~ G + L + S + L*S), family = cumulative(parallel = TRUE), data = auto)
mod2 <- vglm(X1 ~ G + L + S + L*S), family = cumulative(parallel = TRUE), data = auto)
auto.fix = reshape(auto,
varying = c("X1", "X2", "X3", "X4", "X5"),
v.names = "Counts",
timevar = "Type",
times = c("X1", "X2", "X3", "X4", "X5"),
direction = "long")
auto.fix
View(auto.fix)
View(auto)
setwd("/Users/chanm/Desktop/STATclasses/Aaron/STAT426")
CancerR = data.frame(read.csv(file = 'cancer-remission.csv',header = T))
#Problem 1
ungr = data.frame(trials = c(1:12),
x = c(0,0,0,0,1,1,1,1,2,2,2,2),
y = c(1,0,0,0,1,1,0,0,1,1,1,1))
gr =  data.frame(x = c(0,1,2),
n = c(4,4,4),
y = c(1,2,4))
View(CancerR)
View(gr)
View(auto)
mod2 = vglm(cbind(X1,X2,X3,X4,X5) ~ G + L + S, family = cumulative(parallel = TRUE), data = auto)
mod2 = vglm(cbind(X1,X2,X3,X4,X5) ~ G + L + S + L * S, family = cumulative(parallel = TRUE), data = auto)
