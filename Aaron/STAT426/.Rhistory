mod = knnreg(classes ~., data = sim_est,k=d)
mean(predict(mod,sim_val)==sim_val$classes)
}
#make a list
validation_acc_list = map_dbl(k, calc_mod_accuracy)
validation_acc_list
sd(validation_acc_list)
# set seed
set.seed(10)
# simulate data
sim_data = as_tibble(mlbench.spirals(n = 500, sd = 0.15))
# test-train split
sim_trn_idx = sample(nrow(sim_data), size = 0.8 * nrow(sim_data))
sim_trn = sim_data[sim_trn_idx, ]
sim_tst = sim_data[-sim_trn_idx, ]
# estimation-validation split
sim_est_idx = sample(nrow(sim_trn), size = 0.8 * nrow(sim_trn))
sim_est = sim_trn[sim_est_idx, ]
sim_val = sim_trn[-sim_est_idx, ]
# check data
sim_trn
# values of k to consider
k = seq(1, 51, by = 2)
#accuracy function
calc_mod_accuracy = function(d) {
mod = knn3(classes ~., data = sim_est,k=d)
mean(sim_val$classes==predict(mod,sim_val))
}
#make a list
validation_acc_list = map_dbl(k, calc_mod_accuracy)
validation_acc_list
sd(validation_acc_list)
# set seed
set.seed(10)
# simulate data
sim_data = as_tibble(mlbench.spirals(n = 500, sd = 0.15))
# test-train split
sim_trn_idx = sample(nrow(sim_data), size = 0.8 * nrow(sim_data))
sim_trn = sim_data[sim_trn_idx, ]
sim_tst = sim_data[-sim_trn_idx, ]
# estimation-validation split
sim_est_idx = sample(nrow(sim_trn), size = 0.8 * nrow(sim_trn))
sim_est = sim_trn[sim_est_idx, ]
sim_val = sim_trn[-sim_est_idx, ]
# check data
sim_trn
# values of k to consider
k = seq(1, 51, by = 2)
#accuracy function
calc_mod_accuracy = function(d) {
mod = knn3(classes ~., data = sim_est,k=d)
mean(sim_val$classes==predict(mod,sim_val))
}
#make a list
validation_acc_list = map_dbl(k, calc_mod_accuracy)
validation_acc_list
sd(validation_acc_list)
#6.2
# load packages
library("tidyverse")
library("rpart")
library("caret")
library("mlbench")
# set seed
set.seed(10)
# simulate data
sim_data = as_tibble(mlbench.spirals(n = 500, sd = 0.15))
# test-train split
sim_trn_idx = sample(nrow(sim_data), size = 0.8 * nrow(sim_data))
sim_trn = sim_data[sim_trn_idx, ]
sim_tst = sim_data[-sim_trn_idx, ]
# estimation-validation split
sim_est_idx = sample(nrow(sim_trn), size = 0.8 * nrow(sim_trn))
sim_est = sim_trn[sim_est_idx, ]
sim_val = sim_trn[-sim_est_idx, ]
# check data
sim_trn
# values of k to consider
k = seq(1, 51, by = 2)
#accuracy function
calc_mod_accuracy = function(d) {
mod = knnreg(classes ~., data = sim_est,k=d)
mean(sim_val$classes==predict(mod,sim_val))
}
#make a list
validation_acc_list = map_dbl(k, calc_mod_accuracy)
validation_acc_list
sd(validation_acc_list)
# values of k to consider
k = seq(1, 51, by = 2)
#accuracy function
calc_mod_accuracy = function(d) {
mod = knnreg(classes ~., data = sim_est,k=d)
mean(sim_val$classes==predict(mod,sim_val,type="class"))
}
#make a list
validation_acc_list = map_dbl(k, calc_mod_accuracy)
validation_acc_list
sd(validation_acc_list)
k
#6.3
#a&b plug in x1 and x2
#c&d take the exponential after plugging in x1&2
x1 = -.11
x2 =   .74
1.49+ -2.33*(x1) + 1.87*(x2)
#6.3
#a&b plug in x1 and x2
#c&d take the exponential after plugging in x1&2
x1 = .05
x2 =  .96
1.49+ -2.33*(x1) + 1.87*(x2)
#6.3
#a&b plug in x1 and x2
#c&d take the exponential after plugging in x1&2
x1 = .13
x2 = -.51
1.49+ -2.33*(x1) + 1.87*(x2)
exp(1.49+ -2.33*(x1) + 1.87*(x2))
#6.3
#a&b plug in x1 and x2
#c&d take the exponential after plugging in x1&2
x1 = .04
x2 = -.06
1.49+ -2.33*(x1) + 1.87*(x2)
exp(1.49+ -2.33*(x1) + 1.87*(x2))
#6.4
library(boot)
x1 = .36
x2 = -.91
x = -1.75+-1.12*(x1)+-1.93*(x2)
logit(x)
x
inv.logit(x)
x1 = -.63
x2 = .3
x = -1.75+-1.12*(x1)+-1.93*(x2)
inv.logit(x)
x1 = -.89
x2 = .2
x = -1.75+-1.12*(x1)+-1.93*(x2)
inv.logit(x)#for parts a and b
logit(x)
1-inv.logit(x)
x1 = -.54
x2 = .83
x = -1.75+-1.12*(x1)+-1.93*(x2)
inv.logit(x)#for parts a and b
1-inv.logit(x)#for parts c
x1 = .48
x2 = 0
x = -1.75+-1.12*(x1)+-1.93*(x2)
inv.logit(x)#for parts a and b
x1 = -.64
x2 = .26
x = -1.75+-1.12*(x1)+-1.93*(x2)
inv.logit(x)#for parts a and b
x1 = -.33
x2 = .45
x = -1.75+-1.12*(x1)+-1.93*(x2)
inv.logit(x)#for parts a and b
1-inv.logit(x)#for parts c and d
x1 = c(.48,-.64,-.33,-.1)
x2 = c(0,.26,.45,-.8)
xa = -3.97+4.63*(x1[1])+-2.52*(x2[1])
xb = -3.97+4.63*(x1[2])+-2.52*(x2[2])
xc = -3.97+4.63*(x1[3])+-2.52*(x2[3])
xd = -3.97+4.63*(x1[4])+-2.52*(x2[4])
inv.logit(xa)#for parts a and b
inv.logit(xb)
1-inv.logit(xc)#for parts c and d
1-inv.logit(xd)
inv.logit(xd)
1-
x1 = c(.48,-.64,-.33,-.1)
x2 = c(0,.26,.45,-.8)
logs = (-1.58,-1.64,-1.15)
x1 = c(.48,-.64,-.33,-.1)
x2 = c(0,.26,.45,-.8)
logs = c(-1.58,-1.64,-1.15)
xa = logs[1]+logs[2]*(x1[1])+logs[3]*(x2[1])
xb = logs[1]+logs[2]*(x1[2])+logs[3]*(x2[2])
xc = logs[1]+logs[2]*(x1[3])+logs[3]*(x2[3])
xd = logs[1]+logs[2]*(x1[4])+logs[3]*(x2[4])
inv.logit(xa)#for parts a and b
inv.logit(xb)
1-inv.logit(xc)#for parts c and d
1-inv.logit(xd)
x1 = c(.7,.38,-.75,.5)
x2 = c(.63,.25,.6,-.98)
logs = c(-1.58,-1.64,-1.15)
xa = logs[1]+logs[2]*(x1[1])+logs[3]*(x2[1])
xb = logs[1]+logs[2]*(x1[2])+logs[3]*(x2[2])
xc = logs[1]+logs[2]*(x1[3])+logs[3]*(x2[3])
xd = logs[1]+logs[2]*(x1[4])+logs[3]*(x2[4])
inv.logit(xa)#for parts a and b
inv.logit(xb)
1-inv.logit(xc)#for parts c and d
1-inv.logit(xd)
x1 = c(.84,.68,.07,.62)
x2 = c(-.7,.55,.96,.86)
logs = c(4.65,-4.06,1.51)
xa = logs[1]+logs[2]*(x1[1])+logs[3]*(x2[1])
xb = logs[1]+logs[2]*(x1[2])+logs[3]*(x2[2])
xc = logs[1]+logs[2]*(x1[3])+logs[3]*(x2[3])
xd = logs[1]+logs[2]*(x1[4])+logs[3]*(x2[4])
inv.logit(xa)#for parts a and b
inv.logit(xb)
1-inv.logit(xc)#for parts c and d
1-inv.logit(xd)
#6.5
#log(p(x)/1-p(x))=log(.5/.5)=0
#given x1 we can now solve for x2, plug and solve
logs = c(2.29,-.76,.77)
x1 = c(-.8,.21)
x2 = c(-.48,.78)
(-logs[1]-logs[2]*x1[1])/logs[3]
(-logs[1]-logs[2]*x1[1])/logs[3]
(-logs[1]-logs[2]*x1[2])/logs[3]
(-logs[1]-logs[3]*x2[1])/logs[2]
(-logs[1]-logs[3]*x2[2])/logs[2]
#6.2
# load packages
library("tidyverse")
library("rpart")
library("caret")
library("mlbench")
# set seed
set.seed(10)
# simulate data
sim_data = as_tibble(mlbench.spirals(n = 500, sd = 0.15))
# test-train split
sim_trn_idx = sample(nrow(sim_data), size = 0.8 * nrow(sim_data))
sim_trn = sim_data[sim_trn_idx, ]
sim_tst = sim_data[-sim_trn_idx, ]
# estimation-validation split
sim_est_idx = sample(nrow(sim_trn), size = 0.8 * nrow(sim_trn))
sim_est = sim_trn[sim_est_idx, ]
sim_val = sim_trn[-sim_est_idx, ]
# check data
sim_trn
# values of k to consider
k = seq(1, 51, by = 2)
#accuracy function
calc_mod_accuracy = function(d) {
mod = knnreg(classes ~., data = sim_est,k=d)
mean(sim_val$classes==predict(mod,sim_val,type="class"))
}
#make a list
validation_acc_list = map_dbl(1:51, calc_mod_accuracy)
validation_acc_list
sd(validation_acc_list)
#make a list
validation_acc_list = map_dbl(3, calc_mod_accuracy)
validation_acc_list
sd(validation_acc_list)
# set seed
set.seed(8)
# simulate data
sim_data = as_tibble(mlbench.spirals(n = 500, sd = 0.15))
# test-train split
sim_trn_idx = sample(nrow(sim_data), size = 0.8 * nrow(sim_data))
sim_trn = sim_data[sim_trn_idx, ]
sim_tst = sim_data[-sim_trn_idx, ]
# estimation-validation split
sim_est_idx = sample(nrow(sim_trn), size = 0.8 * nrow(sim_trn))
sim_est = sim_trn[sim_est_idx, ]
sim_val = sim_trn[-sim_est_idx, ]
# check data
sim_trn
# values of k to consider
k = seq(1, 51, by = 2)
#accuracy function
calc_mod_accuracy = function(d) {
mod = knnreg(classes ~., data = sim_est,k=d)
mean(sim_val$classes==predict(mod,sim_val,type="class"))
}
#make a list
validation_acc_list = map_dbl(k, calc_mod_accuracy)
validation_acc_list
sd(validation_acc_list)
#6.6
# function to generate data
gen_logistic_data = function(sample_size = 100) {
x1 = round(runif(n = sample_size), 2)
x2 = round(runif(n = sample_size), 2)
nu = 2 + 3 * x1 + -5 * x2
y = rbinom(n = sample_size, size = 1, prob = boot::inv.logit(nu))
data.frame(y, x1, x2)
}
# simulating the data
set.seed(42)
some_data = gen_logistic_data()
# checking the data
head(some_data)
B0 = c(-.84,-.64,1.08)
B1 = c(4.25,.72,.25)
B2 = c(3.24,-.36,5)
a=B0[1]+ B1[1]*(some_data$x1)-B2[1]*(some_data$x2)
b=B0[2]+ B1[2]*(some_data$x1)-B2[2]*(some_data$x2)
c=B0[3]+ B1[3]*(some_data$x1)-B2[3]*(some_data$x2)
pa=1/(1+exp(-a))
pb=1/(1+exp(-b))
pc=1/(1+exp(-c))
sum(log(dbinom(some_data$y,1,pa)))
sum(log(dbinom(some_data$y,1,pb)))
sum(log(dbinom(some_data$y,1,pc)))
#6.6
# function to generate data
gen_logistic_data = function(sample_size = 100) {
x1 = round(runif(n = sample_size), 2)
x2 = round(runif(n = sample_size), 2)
nu = 2 + 3 * x1 + -5 * x2
y = rbinom(n = sample_size, size = 1, prob = boot::inv.logit(nu))
data.frame(y, x1, x2)
}
# simulating the data
set.seed(42)
some_data = gen_logistic_data()
# checking the data
head(some_data)
B0 = c(-.84,-.64,1.08)
B1 = c(4.25,.72,.25)
B2 = c(3.24,-.36,5)
a=B0[1]+ B1[1]*(some_data$x1)-B2[1]*(some_data$x2)
b=B0[2]+ B1[2]*(some_data$x1)-B2[2]*(some_data$x2)
c=B0[3]+ B1[3]*(some_data$x1)-B2[3]*(some_data$x2)
pa=1/(1+exp(-a))
pb=1/(1+exp(-b))
pc=1/(1+exp(-c))
sum(log(dbinom(some_data$y,1,pa)))
sum(log(dbinom(some_data$y,1,pb)))
sum(log(dbinom(some_data$y,1,pc)))
#6.5
#log(p(x)/1-p(x))=log(.5/.5)=0
#given x1 we can now solve for x2, plug and solve
logs = c(2.29,-.76,.77)
x1 = c(-.8,.21)
x2 = c(-.48,.78)
(-logs[1]-logs[2]*x1[1])/logs[3]
(-logs[1]-logs[2]*x1[2])/logs[3]
(-logs[1]-logs[3]*x2[1])/logs[2]
(-logs[1]-logs[3]*x2[2])/logs[2]
#6.6
# function to generate data
gen_logistic_data = function(sample_size = 100) {
x1 = round(runif(n = sample_size), 2)
x2 = round(runif(n = sample_size), 2)
nu = 2 + 3 * x1 + -5 * x2
y = rbinom(n = sample_size, size = 1, prob = boot::inv.logit(nu))
data.frame(y, x1, x2)
}
# simulating the data
set.seed(42)
some_data = gen_logistic_data()
# checking the data
head(some_data)
B0 = c(-.84,-.64,1.08)
B1 = c(4.25,.72,.25)
B2 = c(3.24,-.36,5)
a=B0[1]+ B1[1]*(some_data$x1)-B2[1]*(some_data$x2)
b=B0[2]+ B1[2]*(some_data$x1)-B2[2]*(some_data$x2)
c=B0[3]+ B1[3]*(some_data$x1)-B2[3]*(some_data$x2)
pa=mean(1/(1+exp(-a)))
pb=mean(1/(1+exp(-b)))
pc=mean(1/(1+exp(-c)))
sum(log(dbinom(some_data$y,1,pa)))
sum(log(dbinom(some_data$y,1,pb)))
sum(log(dbinom(some_data$y,1,pc)))
#6.6
# function to generate data
gen_logistic_data = function(sample_size = 100) {
x1 = round(runif(n = sample_size), 2)
x2 = round(runif(n = sample_size), 2)
nu = 2 + 3 * x1 + -5 * x2
y = rbinom(n = sample_size, size = 1, prob = boot::inv.logit(nu))
data.frame(y, x1, x2)
}
# simulating the data
set.seed(42)
some_data = gen_logistic_data()
# checking the data
head(some_data)
B0 = c(-.84,-.64,1.08)
B1 = c(4.25,.72,.25)
B2 = c(3.24,-.36,5)
a=B0[1]+ B1[1]*(some_data$x1)-B2[1]*(some_data$x2)
b=B0[2]+ B1[2]*(some_data$x1)-B2[2]*(some_data$x2)
c=B0[3]+ B1[3]*(some_data$x1)-B2[3]*(some_data$x2)
pa=mean(1/(1+exp(-a)))
pb=mean(1/(1+exp(-b)))
pc=mean(1/(1+exp(-c)))
sum(log(dbinom(some_data$y,1,pb)))
sum(log(dbinom(some_data$y,1,pc)))
sum(log(dbinom(some_data$y,1,pa)))
a
b
a=B0[1]+ B1[1]*(some_data$x1)-B2[1]*(some_data$x2)
b=B0[2]+ B1[2]*(some_data$x1)-B2[2]*(some_data$x2)
c=B0[3]+ B1[3]*(some_data$x1)-B2[3]*(some_data$x2)
pa=1/(1+exp(-a))
pb=1/(1+exp(-b))
pc=1/(1+exp(-c))
p
PA
PA
pa
log(dbinom(some_data$y,1,pa))
log(dbinom(some_data$y,1,pb))
log(dbinom(some_data$y,1,pc))
pa=1/(1+exp(-a))
pa
#Problem 1
#a
setwd("/Users/chanm/Desktop/STATclasses/Aaron/STAT426")
horseshoe = read.table("horseshoe.txt", header=TRUE)
head(horseshoe)
horseshoe.ols = lm(y ~ weight, data = horseshoe)
summary(horseshoe.ols)
predict(horseshoe.ols, data.frame(weight = 5200), type = "response")
#Problem 2
#a
#Organizing data
Smoke.dat = data.frame(
Age = c(rep("35-44",2),rep("45-54",2),rep("55-64",2),rep("65-74",2),rep("75-85",2)),
PersonYears = c(18793,52407,10673,43248,5710,28612,2585,12663,1462,5317),
Smoke = c(rep(c("no","yes"),5)),
Deaths = c(2,32,12,104,28,206,28,186,31,102)
)
#Calculate cornonary death rate
DRate = Smoke.dat[,4]/Smoke.dat[,2]
#Add the new column to the data
Smoke.dat = cbind(Smoke.dat,DRate)
Smoke.dat
#Ratio of Death Rates for Smoking to Non-smoking
DRate_Smoke = Smoke.dat[Smoke.dat$Smoke == "yes",]$DRate
DRate_NoSmoke = Smoke.dat[Smoke.dat$Smoke == "no",]$DRate
Ratio = DRate_Smoke/DRate_NoSmoke
#By Age group
ratios.dat = data.frame(
Age = c("35-44","45-54","55-64","65-74","75-85")
)
ratios.dat = cbind(ratios.dat,Ratio)
ratios.dat
#b
mainEfftects = glm(Deaths ~ Age + Smoke, family = poisson, offset = log(PersonYears), data = Smoke.dat)
summary(mainEfftects)
mainEfftects
summary(mainEfftects)
#b
mainEfftects = glm(Deaths ~ Age + Smoke, family = poisson, offset = log(PersonYears), data = Smoke.dat)
mainEfftects
#Assign Scores
Smoke.dat
#Assign Scores
Smoke.dat = data.frame(
AgeScore = c(rep(1,2),rep(2,2),rep(3,2),rep(4,2),rep(5,2)),
PersonYears = c(18793,52407,10673,43248,5710,28612,2585,12663,1462,5317),
Smoke = c(rep(c("no","yes"),5)),
Deaths = c(2,32,12,104,28,206,28,186,31,102)
)
#Assign Scores
Smoke.datNew = data.frame(
AgeScore = c(rep(1,2),rep(2,2),rep(3,2),rep(4,2),rep(5,2)),
PersonYears = c(18793,52407,10673,43248,5710,28612,2585,12663,1462,5317),
Smoke = c(rep(c("no","yes"),5)),
Deaths = c(2,32,12,104,28,206,28,186,31,102)
)
SmokeQuant = glm(Deaths ~ AgeScore*Smoke, family = poisson, data = Smoke.datNew, offset = log(PersonYears))
SmokeQuant
#Problem 2
#a
#Organizing data
Smoke.dat = data.frame(
Age = c(rep("35-44",2),rep("45-54",2),rep("55-64",2),rep("65-74",2),rep("75-85",2)),
PersonYears = c(18793,52407,10673,43248,5710,28612,2585,12663,1462,5317),
Smoke = c(rep(c("no","yes"),5)),
Deaths = c(2,32,12,104,28,206,28,186,31,102)
)
#Calculate cornonary death rate
DRate = Smoke.dat[,4]/Smoke.dat[,2]
Smoke.dat
#Ratio of Death Rates for Smoking to Non-smoking
DRate_Smoke = Smoke.dat[Smoke.dat$Smoke == "yes",]$DRate
#Add the new column to the data
Smoke.dat = cbind(Smoke.dat,DRate)
DRate_NoSmoke = Smoke.dat[Smoke.dat$Smoke == "no",]$DRate
Ratio = DRate_Smoke/DRate_NoSmoke
#By Age group
ratios.dat = data.frame(
Age = c("35-44","45-54","55-64","65-74","75-85")
)
ratios.dat = cbind(ratios.dat,Ratio)
ratios.dat
#b
mainEfftects = glm(Deaths ~ Age + Smoke, family = poisson, offset = log(PersonYears), data = Smoke.dat)
mainEfftects
#Assign Scores
Smoke.datNew = data.frame(
AgeScore = c(rep(1,2),rep(2,2),rep(3,2),rep(4,2),rep(5,2)),
PersonYears = c(18793,52407,10673,43248,5710,28612,2585,12663,1462,5317),
Smoke = c(rep(c("no","yes"),5)),
Deaths = c(2,32,12,104,28,206,28,186,31,102)
)
SmokeQuant = glm(Deaths ~ AgeScore*Smoke, family = poisson, offset = log(PersonYears), data = Smoke.datNew)
SmokeQuant
#
#
#
#
#b
horseshoe.ML = glm(y ~ weight, family = binomial(link=identity), data = horseshoe)
