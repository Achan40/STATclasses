head(bwt_trn)
#KNN prediction
mod_k = knnreg(bwt~lwt + age + smoke,data = bwt_trn,k=19)
predictK = data.frame(age = 31, lwt = 124, smoke = factor(levels(bwt_trn$smoke)))
predict(mod_k,predictK)
#descision tree prediction
tree_1 = rpart(bwt~lwt + age + smoke,data = bwt_trn,cp = .5)
predictTree = data.frame(age = 29, lwt = 132, smoke = factor(levels(bwt_trn$smoke)))
predict(tree_1,predictTree)
#Linear and KNN
mods = list(
mod_inter = lm(bwt~1,data = bwt_est),#model w only an intercept
mod_k = knnreg(bwt~lwt + age + smoke,data = bwt_trn,k=count(bwt_est))
)
mom1 = data.frame(age = 33, lwt = 129,smoke=factor(levels(bwt_est$smoke)))
mom2 = data.frame(age = 29, lwt = 118,smoke=factor(levels(bwt_est$smoke)))
mom3 = data.frame(age = 37, lwt = 113,smoke=factor(levels(bwt_est$smoke)))
predict(mods,mom1)
predict(mods,mom2)
predict(mods,mom3)
#KNN all variables
mod_k_all = knnreg(bwt~., data = bwt_est,k=1)#have to turn mod_k_all into a list to work w map function
#Validation RMSE [est to val]
calc_RMSE(act = bwt_val$bwt,pred = predict(mod_k_all,bwt_val))
#TrainRMSE [est to est in this case]
calc_RMSE(act = bwt_est$bwt,pred = predict(mod_k_all,bwt_est))
#descision tree all variable
dtree_all = rpart(bwt~., data = bwt_est, cp=0,minsplit=2)
#Validation RMSE [est to val]
calc_RMSE(act = bwt_val$bwt,pred = predict(dtree_all,bwt_val))
#TrainRMSE [est to est in this case] since only one model
calc_RMSE(act = bwt_est$bwt,pred = predict(dtree_all,bwt_est))
#KNN all variables different K, least flex, highest K
mod_list = list(
mod_k_all1 = knnreg(bwt~.,data = bwt_est, k=14),
mod_k_all2 = knnreg(bwt~.,data = bwt_est, k=26),
mod_k_all3 = knnreg(bwt~.,data = bwt_est, k=48)
)
#calculation for validation RMSE [est to val]
val_pred = map(mod_list, predict, bwt_val)
map_dbl(val_pred,calc_RMSE, act = bwt_val$bwt)
#RMSETest [trn to tst] lowest RMSE
mod_final = knnreg(bwt~.,data = bwt_trn, k=48)
calc_RMSE(act = bwt_tst$bwt,pred = predict(mod_final,bwt_tst))
#Descision Tree all variables, different cp
mod_list = list(
mod_t_all1 = rpart(bwt~.,data = bwt_est, cp=.1, minsplit = 2),
mod_t_all2 = rpart(bwt~.,data = bwt_est, cp=.01, minsplit = 2),
mod_t_all3 = rpart(bwt~.,data = bwt_est, cp=.001, minsplit = 2)
)
#calculation for validation RMSE [est to val]
val_pred = map(mod_list, predict, bwt_val)
map_dbl(val_pred,calc_RMSE, act = bwt_val$bwt)
#RMSETest [trn to tst] lowest RMSE
mod_final = rpart(bwt~.,data = bwt_trn, cp=.1, minsplit = 2)
calc_RMSE(act = bwt_tst$bwt,pred = predict(mod_final,bwt_tst))
#3.9&3.10&3.11&3.12&3.13
# set seed
set.seed(16159)
# load data
bwt = as_tibble(MASS::birthwt)
# data prep
bwt = bwt %>%
select(-low, -ht, -ui) %>%
mutate(race = factor(race, labels = c("white", "black", "other")),
smoke = factor(smoke, labels = c("non-smoker", "smoker")))
# test-train split
bwt_trn_idx = sample(nrow(bwt), size = 0.8 * nrow(bwt))
bwt_trn = bwt[bwt_trn_idx, ]
bwt_tst = bwt[-bwt_trn_idx, ]
# estimation-validation split
bwt_est_idx = sample(nrow(bwt_trn), size = 0.8 * nrow(bwt_trn))
bwt_est = bwt_trn[bwt_est_idx, ]
bwt_val = bwt_trn[-bwt_est_idx, ]
# check data
head(bwt_trn)
#KNN prediction
mod_k = knnreg(bwt~lwt + age + smoke,data = bwt_trn,k=19)
predictK = data.frame(age = 31, lwt = 124, smoke = factor(levels(bwt_trn$smoke)))
predict(mod_k,predictK)
#descision tree prediction
tree_1 = rpart(bwt~lwt + age + smoke,data = bwt_trn,cp = .5)
predictTree = data.frame(age = 29, lwt = 132, smoke = factor(levels(bwt_trn$smoke)))
predict(tree_1,predictTree)
#Linear and KNN
mods = list(
mod_inter = lm(bwt~1,data = bwt_est),#model w only an intercept
mod_k = knnreg(bwt~lwt + age + smoke,data = bwt_trn,k=count(bwt_est))
)
mom1 = data.frame(age = 33, lwt = 129,smoke=factor(levels(bwt_est$smoke)))
mom2 = data.frame(age = 29, lwt = 118,smoke=factor(levels(bwt_est$smoke)))
mom3 = data.frame(age = 37, lwt = 113,smoke=factor(levels(bwt_est$smoke)))
predict(mods,mom1)
predict(mods,mom2)
predict(mods,mom3)
#KNN all variables
mod_k_all = knnreg(bwt~., data = bwt_est,k=1)#have to turn mod_k_all into a list to work w map function
#Validation RMSE [est to val]
calc_RMSE(act = bwt_val$bwt,pred = predict(mod_k_all,bwt_val))
#TrainRMSE [est to est in this case]
calc_RMSE(act = bwt_est$bwt,pred = predict(mod_k_all,bwt_est))
#descision tree all variable
dtree_all = rpart(bwt~., data = bwt_est, cp=0,minsplit=2)
#Validation RMSE [est to val]
calc_RMSE(act = bwt_val$bwt,pred = predict(dtree_all,bwt_val))
#TrainRMSE [est to est in this case] since only one model
calc_RMSE(act = bwt_est$bwt,pred = predict(dtree_all,bwt_est))
#KNN all variables different K, least flex, highest K
mod_list = list(
mod_k_all1 = knnreg(bwt~.,data = bwt_est, k=14),
mod_k_all2 = knnreg(bwt~.,data = bwt_est, k=26),
mod_k_all3 = knnreg(bwt~.,data = bwt_est, k=48)
)
#calculation for validation RMSE [est to val]
val_pred = map(mod_list, predict, bwt_val)
map_dbl(val_pred,calc_RMSE, act = bwt_val$bwt)
#RMSETest [trn to tst] lowest RMSE
mod_final = knnreg(bwt~.,data = bwt_trn, k=48)
calc_RMSE(act = bwt_tst$bwt,pred = predict(mod_final,bwt_tst))
#Descision Tree all variables, different cp
mod_list = list(
mod_t_all1 = rpart(bwt~.,data = bwt_est, cp=.1, minsplit = 2),
mod_t_all2 = rpart(bwt~.,data = bwt_est, cp=.01, minsplit = 2),
mod_t_all3 = rpart(bwt~.,data = bwt_est, cp=.001, minsplit = 2)
)
#calculation for validation RMSE [est to val] least flexible is highest cp
val_pred = map(mod_list, predict, bwt_val)
map_dbl(val_pred,calc_RMSE, act = bwt_val$bwt)
#RMSETest [trn to tst] lowest RMSE
mod_final = rpart(bwt~.,data = bwt_trn, cp=.1, minsplit = 2)
calc_RMSE(act = bwt_tst$bwt,pred = predict(mod_final,bwt_tst))
dnorm(9.9,6,1.5)
dnorm(9.9,8.9,1.5)
dnorm(9.9,9.1,1.5)
#5.11
prior = c(.47,.26,.27)
dnorm(9.9,6,1.5)*prior[1]
dnorm(9.9,8.9,1.5)*prior[2]
dnorm(9.9,9.1,1.5)*prior[3]
#5.11
prior = c(.09,.64,.27)
dnorm(5.7,8,1.5)*prior[1]
dnorm(5.7,8.3,1.5)*prior[2]
dnorm(5.7,8.7,1.5)*prior[3]
#5.12
prior = c(.13,.44,.43)
X=3
dnorm(X,3.71)*prior[1]
dnorm(X,5.75)*prior[2]
dnorm(X,8.22)*prior[3]
dpois(X,3.71)*prior[1]
dpois(X,5.75)*prior[2]
dpois(X,8.22)*prior[3]
#5.12
prior = c(.35,.39,.26)
X=3
dpois(X,2.5)*prior[1]
dpois(X,4.67)*prior[2]
dpois(X,4.96)*prior[3]
#5.12
prior = c(.35,.39,.26)
X=5
dpois(X,2.5)*prior[1]
dpois(X,4.67)*prior[2]
dpois(X,4.96)*prior[3]
#5.12
prior = c(.21,.5,.29)
X=4
dpois(X,4.43)*prior[1]
dpois(X,4.8)*prior[2]
dpois(X,8.6)*prior[3]
#5.14
# load packages
library("mlbench")
library("tibble")
library("caret")
library("rpart")
# set seed
set.seed(43329)
# generate data
class_data = mlbench.simplex(n = 800, d = 2, sd = 0.5)
class_data = as_tibble(class_data)
head(class_data)
knn3(classes~.,data = class_data)
knn3(classes~.,k=4,data = class_data)
predictdata = data.frame(x.1 = .88,x.2=-.13)
knn3(classes~.,k=4,data = class_data)
predict(mod1,predictdata)
()
()
#make model and data to use for predict()
mod1 = knn3(classes~.,k=4,data = class_data)
predictdata_prob = data.frame(x.1 = .88,x.2=-.13)
predictdata = data.frame(x.1=1.46,x.2=.34)
predict(mod1,predictdata)
predict(mod1,predictdata,type="response")
predict(mod1,predictdata,type="prob")
#make model and data to use for predict()
mod1 = knn3(classes~.,k=4,data = class_data)
predictdata_prob = data.frame(x.1 = .88,x.2=-.13)
predictdata = data.frame(x.1=1.46,x.2=.34)
predict(mod1,predictdata_prob,type="prob")
predict(mod1,predictdata,type = "class")
# generate data
class_data = mlbench.simplex(n = 800, d = 2, sd = 0.5)
class_data = as_tibble(class_data)
# set seed
set.seed(74656)
# generate data
class_data = mlbench.simplex(n = 800, d = 2, sd = 0.5)
class_data = as_tibble(class_data)
#make model and data to use for predict()
mod1 = knn3(classes~.,k=5,data = class_data)
predictdata_prob = data.frame(x.1 = -.29,x.2=.37)
predictdata = data.frame(x.1=2.29,x.2=-1.47)
predict(mod1,predictdata_prob,type="prob")
predict(mod1,predictdata,type = "class")
# set seed
set.seed(82451)
# generate data
class_data = mlbench.simplex(n = 800, d = 2, sd = 0.5)
class_data = as_tibble(class_data)
#make KNN model and data to use for predict()
mod1 = knn3(classes~.,k=5,data = class_data)
predictdata_prob = data.frame(x.1 = -1.22,x.2=.83)
predictdata = data.frame(x.1=-.87,x.2=-1.19)
predict(mod1,predictdata_prob,type="prob")
predict(mod1,predictdata,type = "class")
#make descision tree model
mod2 = rpart(classes~.,data = class_data, cp=1,minsplit=5)
predict(mod2,predictdata_prob,type="prob")
predict(mod2,predictdata,type = "class")
#5.16
# set seed
set.seed(37320)
# load data and coerce to tibble
default = as_tibble(ISLR::Default)
# split data
dft_trn_idx = sample(nrow(default), size = 0.8 * nrow(default))
dft_trn = default[dft_trn_idx, ]
dft_tst = default[-dft_trn_idx, ]
# check data
dft_trn
#5.16
# set seed
set.seed(37320)
# load data and coerce to tibble
default = as_tibble(ISLR::Default)
library("rpart")
#5.16
# load packages
library("mlbench")
library("tibble")
library("caret")
library("rpart")
# set seed
set.seed(37320)
# load data and coerce to tibble
default = as_tibble(ISLR::Default)
# split data
dft_trn_idx = sample(nrow(default), size = 0.8 * nrow(default))
#5.16
# load packages
library("mlbench")
library("tibble")
library("caret")
library("rpart")
# set seed
set.seed(37320)
# load data and coerce to tibble
default = as_tibble(ISLR::Default)
install.packages("ISLR")
library("ISLR")
# set seed
set.seed(37320)
# load data and coerce to tibble
default = as_tibble(ISLR::Default)
# split data
dft_trn_idx = sample(nrow(default), size = 0.8 * nrow(default))
dft_trn = default[dft_trn_idx, ]
dft_tst = default[-dft_trn_idx, ]
# check data
dft_trn
mod3 = knn3(default~.,data = dft_trn)
predict(mod3,predictdata,type = "prob")
mod3 = knn3(default~.,data = dft_trn)
predictdata = data.frame(balance=321,income=37640)
predict(mod3,predictdata,type = "prob")
predictdata = data.frame(balance=321,income=37640,factor(levels(student)))
predictdata = data.frame(balance=321,income=37640,factor(levels(dft_trn$student)))
predict(mod3,predictdata,type = "prob")
mod3 = knn3(default~.,data = dft_trn)
predictdata = data.frame(balance=321,income=37640,factor(levels(dft_trn$student)))
predict(mod3,predictdata,type = "prob")
predictdata = data.frame(balance=321,income=37640,student = factor(levels(dft_trn$student)))
predict(mod3,predictdata,type = "prob")
# set seed
set.seed(12922)
# load data and coerce to tibble
default = as_tibble(ISLR::Default)
# split data
dft_trn_idx = sample(nrow(default), size = 0.8 * nrow(default))
dft_trn = default[dft_trn_idx, ]
dft_tst = default[-dft_trn_idx, ]
# check data
dft_trn
#knnmodel
mod3 = knn3(default~.,data = dft_trn)
predictdata = data.frame(balance=321,income=37640,student = factor(levels(dft_trn$student)))
predict(mod3,predictdata,type = "prob")
#desTree model
mod4 = rpart(default~.,data = dft_trn, cp=.001, minsplit=10)
predictdata = data.frame(balance=1189,income=33455,student = factor(levels(dft_trn$student)))
predict(mod4,predictdata,type = "prob")
print(mod5)
#another KNNmodel
mod5 =  knn3(default~.,data = dft_trn, k=13)
print(mod5)
# set seed
set.seed(30335)
# load data and coerce to tibble
default = as_tibble(ISLR::Default)
# split data
dft_trn_idx = sample(nrow(default), size = 0.8 * nrow(default))
dft_trn = default[dft_trn_idx, ]
dft_tst = default[-dft_trn_idx, ]
# check data
dft_trn
#knnmodel
mod3 = knn3(default~.,data = dft_trn)
predictdata = data.frame(balance=321,income=37640,student = factor(levels(dft_trn$student)))
predict(mod3,predictdata,type = "prob")
#desTree model
mod4 = rpart(default~.,data = dft_trn, cp=.001, minsplit=10)
predictdata = data.frame(balance=1189,income=33455,student = factor(levels(dft_trn$student)))
predict(mod4,predictdata,type = "prob")
#another KNNmodel
mod5 =  knn3(default~.,data = dft_trn, k=13)
print(mod5)
mod5 =  knn3(default~.,data = dft_tst, k=13)
#another KNNmodel
mod5 =  knn3(default~.,data = dft_trn, k=13)
mod6 =  knn3(default~.,data = dft_tst, k=13)
print(mod5)
print(mod6)
predict(mod5,dft_trn)
#another KNNmodel
mod5 =  knn3(default~.,data = dft_trn, k=13)
calc_accuracy = function(actual, predicted) {
mean(actual == predicted)
}
calc_accuracy(dft_tst$default,predict(mod5,dft_trn))
calc_accuracy(dft_tst$default,predict(mod5,dft_trn,type="class"))
# set seed
set.seed(30335)
# load data and coerce to tibble
default = as_tibble(ISLR::Default)
# split data
dft_trn_idx = sample(nrow(default), size = 0.8 * nrow(default))
dft_tst = default[-dft_trn_idx, ]
dft_trn = default[dft_trn_idx, ]
# check data
dft_trn
#knnmodel
mod3 = knn3(default~.,data = dft_trn)
predictdata = data.frame(balance=321,income=37640,student = factor(levels(dft_trn$student)))
predict(mod3,predictdata,type = "prob")
#desTree model
mod4 = rpart(default~.,data = dft_trn, cp=.001, minsplit=10)
predictdata = data.frame(balance=1189,income=33455,student = factor(levels(dft_trn$student)))
predict(mod4,predictdata,type = "prob")
#another KNNmodel
mod5 =  knn3(default~.,data = dft_trn, k=13)
calc_accuracy = function(actual, predicted) {
mean(actual == predicted)
}
calc_accuracy(dft_tst$default,predict(mod5,dft_trn,type="class"))
calc_accuracy(dft_tst$default,predict(mod5,dft_tst,type="class"))
# set seed
set.seed(76322)
# load data and coerce to tibble
default = as_tibble(ISLR::Default)
# split data
dft_trn_idx = sample(nrow(default), size = 0.8 * nrow(default))
dft_trn = default[dft_trn_idx, ]
dft_tst = default[-dft_trn_idx, ]
# check data
dft_trn
#knnmodel
mod3 = knn3(default~.,data = dft_trn)
predictdata = data.frame(balance=321,income=37640,student = factor(levels(dft_trn$student)))
predict(mod3,predictdata,type = "prob")
#desTree model
mod4 = rpart(default~.,data = dft_trn, cp=.001, minsplit=10)
predictdata = data.frame(balance=1189,income=33455,student = factor(levels(dft_trn$student)))
predict(mod4,predictdata,type = "prob")
#another KNNmodel
mod5 =  knn3(default~.,data = dft_trn, k=9)
#make a function comparing actual values[tst] to predicted[trn]
calc_accuracy = function(actual, predicted) {
mean(actual == predicted)#average of how many actual values equal to predicted values gives us the accuracy
}
calc_accuracy(dft_tst$default,predict(mod5,dft_tst,type="class"))
#last des Treemodel
mod6 = rpart(default~.,data = dft_trn, cp=.001, minsplit=10)
# set seed
set.seed(29637)
# load data and coerce to tibble
default = as_tibble(ISLR::Default)
# split data
dft_trn_idx = sample(nrow(default), size = 0.8 * nrow(default))
dft_trn = default[dft_trn_idx, ]
dft_tst = default[-dft_trn_idx, ]
# check data
dft_trn
#knnmodel
mod3 = knn3(default~.,data = dft_trn)
predictdata = data.frame(balance=321,income=37640,student = factor(levels(dft_trn$student)))
predict(mod3,predictdata,type = "prob")
#desTree model
mod4 = rpart(default~.,data = dft_trn, cp=.001, minsplit=10)
predictdata = data.frame(balance=1189,income=33455,student = factor(levels(dft_trn$student)))
predict(mod4,predictdata,type = "prob")
#another KNNmodel
mod5 =  knn3(default~.,data = dft_trn, k=9)
#make a function comparing actual values[tst] to predicted[trn]
calc_accuracy = function(actual, predicted) {
mean(actual == predicted)#average of how many actual values equal to predicted values gives us the accuracy
}
calc_accuracy(dft_tst$default,predict(mod5,dft_tst,type="class"))
#last des Treemodel
mod6 = rpart(default~.,data = dft_trn, cp=.001, minsplit=10)
1-calc_accuracy(dft_tst$default,predict(mod6,dft_tst,type="class"))
1-calc_accuracy(dft_tst$default,predict(mod6,dft_tst,type="prob"))
1-calc_accuracy(dft_tst$default,predict(mod6,dft_tst,type="class"))
#last des Treemodel
mod6 = rpart(default~.,data = dft_trn, cp=.001, minsplit=10)
calc_misclass = function(actual, predicted) {
mean(actual != predicted)#average of how many actual values equal to predicted values gives us the accuracy
}
calc_misclass(dft_tst$default,predict(mod6,dft_tst,type="class"))
# set seed
set.seed(29637)
# load data and coerce to tibble
default = as_tibble(ISLR::Default)
# split data
dft_trn_idx = sample(nrow(default), size = 0.8 * nrow(default))
dft_trn = default[dft_trn_idx, ]
dft_tst = default[-dft_trn_idx, ]
# check data
dft_trn
#knnmodel
mod3 = knn3(default~.,data = dft_trn)
predictdata = data.frame(balance=321,income=37640,student = factor(levels(dft_trn$student)))
predict(mod3,predictdata,type = "prob")
#desTree model
mod4 = rpart(default~.,data = dft_trn, cp=.001, minsplit=10)
predictdata = data.frame(balance=1189,income=33455,student = factor(levels(dft_trn$student)))
predict(mod4,predictdata,type = "prob")
#another KNNmodel
mod5 =  knn3(default~.,data = dft_trn, k=9)
#make a function comparing actual values[tst] to predicted[trn]
calc_accuracy = function(actual, predicted) {
mean(actual == predicted)#average of how many actual values equal to predicted values gives us the accuracy
}
calc_accuracy(dft_tst$default,predict(mod5,dft_tst,type="class"))
#last des Treemodel
mod6 = rpart(default~.,data = dft_trn, cp=.001, minsplit=10)
calc_misclass = function(actual, predicted) {
mean(actual != predicted)#average of how many actual values equal to predicted values gives us the accuracy
}
calc_misclass(dft_tst$default,predict(mod6,dft_tst,type="class"))
calc_misclass(dft_trn$default,predict(mod6,dft_tst,type="class"))
calc_misclass(dft_tst$default,predict(mod6,dft_trn,type="class"))
calc_misclass(dft_tst$default,predict(mod6,dft_tst,type="class"))
# set seed
set.seed(35188)
# load data and coerce to tibble
default = as_tibble(ISLR::Default)
# split data
dft_trn_idx = sample(nrow(default), size = 0.8 * nrow(default))
# set seed
set.seed(35188)
# load data and coerce to tibble
default = as_tibble(ISLR::Default)
# split data
dft_trn_idx = sample(nrow(default), size = 0.8 * nrow(default))
dft_trn = default[dft_trn_idx, ]
dft_tst = default[-dft_trn_idx, ]
# check data
dft_trn
#knnmodel
mod3 = knn3(default~.,data = dft_trn)
predictdata = data.frame(balance=321,income=37640,student = factor(levels(dft_trn$student)))
predict(mod3,predictdata,type = "prob")
#desTree model
mod4 = rpart(default~.,data = dft_trn, cp=.001, minsplit=10)
predictdata = data.frame(balance=1189,income=33455,student = factor(levels(dft_trn$student)))
predict(mod4,predictdata,type = "prob")
#another KNNmodel
mod5 =  knn3(default~.,data = dft_trn, k=9)
#make a function comparing actual values[tst] to predicted[trn]
calc_accuracy = function(actual, predicted) {
mean(actual == predicted)#average of how many actual values equal to predicted values gives us the accuracy
}
calc_accuracy(dft_tst$default,predict(mod5,dft_tst,type="class"))
#last des Treemodel
mod6 = rpart(default~.,data = dft_trn, cp=.1, minsplit=10)
calc_misclass = function(actual, predicted) {
mean(actual != predicted)#average of how many actual values equal to predicted values gives us the accuracy
}
calc_misclass(dft_tst$default,predict(mod6,dft_tst,type="class"))
